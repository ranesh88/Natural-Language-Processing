{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8pYdZLymIxnoEWYjLf4d3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranesh88/Natural-Language-Processing/blob/main/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8zo_PEbbk_7",
        "outputId": "60dbef0a-f1eb-4bca-f43d-23ec72099f19"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.tokenize import sent_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from string import punctuation\r\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh86Utpbc7AP"
      },
      "source": [
        "text='''A major drawback of statistical methods is that they require elaborate feature engineering. Since the early 2010s,[16] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT)'''"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lorl9ct_dHwb",
        "outputId": "efba20be-65f3-40f0-9d40-03db2741575c"
      },
      "source": [
        "# python string operation\r\n",
        "text.split()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'major',\n",
              " 'drawback',\n",
              " 'of',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'is',\n",
              " 'that',\n",
              " 'they',\n",
              " 'require',\n",
              " 'elaborate',\n",
              " 'feature',\n",
              " 'engineering.',\n",
              " 'Since',\n",
              " 'the',\n",
              " 'early',\n",
              " '2010s,[16]',\n",
              " 'the',\n",
              " 'field',\n",
              " 'has',\n",
              " 'thus',\n",
              " 'largely',\n",
              " 'abandoned',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'and',\n",
              " 'shifted',\n",
              " 'to',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'for',\n",
              " 'machine',\n",
              " 'learning.',\n",
              " 'Popular',\n",
              " 'techniques',\n",
              " 'include',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'word',\n",
              " 'embeddings',\n",
              " 'to',\n",
              " 'capture',\n",
              " 'semantic',\n",
              " 'properties',\n",
              " 'of',\n",
              " 'words,',\n",
              " 'and',\n",
              " 'an',\n",
              " 'increase',\n",
              " 'in',\n",
              " 'end-to-end',\n",
              " 'learning',\n",
              " 'of',\n",
              " 'a',\n",
              " 'higher-level',\n",
              " 'task',\n",
              " '(e.g.,',\n",
              " 'question',\n",
              " 'answering)',\n",
              " 'instead',\n",
              " 'of',\n",
              " 'relying',\n",
              " 'on',\n",
              " 'a',\n",
              " 'pipeline',\n",
              " 'of',\n",
              " 'separate',\n",
              " 'intermediate',\n",
              " 'tasks',\n",
              " '(e.g.,',\n",
              " 'part-of-speech',\n",
              " 'tagging',\n",
              " 'and',\n",
              " 'dependency',\n",
              " 'parsing).',\n",
              " 'In',\n",
              " 'some',\n",
              " 'areas,',\n",
              " 'this',\n",
              " 'shift',\n",
              " 'has',\n",
              " 'entailed',\n",
              " 'substantial',\n",
              " 'changes',\n",
              " 'in',\n",
              " 'how',\n",
              " 'NLP',\n",
              " 'systems',\n",
              " 'are',\n",
              " 'designed,',\n",
              " 'such',\n",
              " 'that',\n",
              " 'deep',\n",
              " 'neural',\n",
              " 'network-based',\n",
              " 'approaches',\n",
              " 'may',\n",
              " 'be',\n",
              " 'viewed',\n",
              " 'as',\n",
              " 'a',\n",
              " 'new',\n",
              " 'paradigm',\n",
              " 'distinct',\n",
              " 'from',\n",
              " 'statistical',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing.',\n",
              " 'For',\n",
              " 'instance,',\n",
              " 'the',\n",
              " 'term',\n",
              " 'neural',\n",
              " 'machine',\n",
              " 'translation',\n",
              " '(NMT)',\n",
              " 'emphasizes',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'deep',\n",
              " 'learning-based',\n",
              " 'approaches',\n",
              " 'to',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'directly',\n",
              " 'learn',\n",
              " 'sequence-to-sequence',\n",
              " 'transformations,',\n",
              " 'obviating',\n",
              " 'the',\n",
              " 'need',\n",
              " 'for',\n",
              " 'intermediate',\n",
              " 'steps',\n",
              " 'such',\n",
              " 'as',\n",
              " 'word',\n",
              " 'alignment',\n",
              " 'and',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'that',\n",
              " 'was',\n",
              " 'used',\n",
              " 'in',\n",
              " 'statistical',\n",
              " 'machine',\n",
              " 'translation',\n",
              " '(SMT)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnllOWOZejhq"
      },
      "source": [
        "**Tokenization**\r\n",
        "\r\n",
        "Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJBRrGn1dQdW"
      },
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ3eb6acdQw0",
        "outputId": "269fef2f-5d93-430d-c4f4-9bb7455c3ca5"
      },
      "source": [
        "tokens"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'major',\n",
              " 'drawback',\n",
              " 'of',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'is',\n",
              " 'that',\n",
              " 'they',\n",
              " 'require',\n",
              " 'elaborate',\n",
              " 'feature',\n",
              " 'engineering',\n",
              " '.',\n",
              " 'Since',\n",
              " 'the',\n",
              " 'early',\n",
              " '2010s',\n",
              " ',',\n",
              " '[',\n",
              " '16',\n",
              " ']',\n",
              " 'the',\n",
              " 'field',\n",
              " 'has',\n",
              " 'thus',\n",
              " 'largely',\n",
              " 'abandoned',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'and',\n",
              " 'shifted',\n",
              " 'to',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'for',\n",
              " 'machine',\n",
              " 'learning',\n",
              " '.',\n",
              " 'Popular',\n",
              " 'techniques',\n",
              " 'include',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'word',\n",
              " 'embeddings',\n",
              " 'to',\n",
              " 'capture',\n",
              " 'semantic',\n",
              " 'properties',\n",
              " 'of',\n",
              " 'words',\n",
              " ',',\n",
              " 'and',\n",
              " 'an',\n",
              " 'increase',\n",
              " 'in',\n",
              " 'end-to-end',\n",
              " 'learning',\n",
              " 'of',\n",
              " 'a',\n",
              " 'higher-level',\n",
              " 'task',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'question',\n",
              " 'answering',\n",
              " ')',\n",
              " 'instead',\n",
              " 'of',\n",
              " 'relying',\n",
              " 'on',\n",
              " 'a',\n",
              " 'pipeline',\n",
              " 'of',\n",
              " 'separate',\n",
              " 'intermediate',\n",
              " 'tasks',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'part-of-speech',\n",
              " 'tagging',\n",
              " 'and',\n",
              " 'dependency',\n",
              " 'parsing',\n",
              " ')',\n",
              " '.',\n",
              " 'In',\n",
              " 'some',\n",
              " 'areas',\n",
              " ',',\n",
              " 'this',\n",
              " 'shift',\n",
              " 'has',\n",
              " 'entailed',\n",
              " 'substantial',\n",
              " 'changes',\n",
              " 'in',\n",
              " 'how',\n",
              " 'NLP',\n",
              " 'systems',\n",
              " 'are',\n",
              " 'designed',\n",
              " ',',\n",
              " 'such',\n",
              " 'that',\n",
              " 'deep',\n",
              " 'neural',\n",
              " 'network-based',\n",
              " 'approaches',\n",
              " 'may',\n",
              " 'be',\n",
              " 'viewed',\n",
              " 'as',\n",
              " 'a',\n",
              " 'new',\n",
              " 'paradigm',\n",
              " 'distinct',\n",
              " 'from',\n",
              " 'statistical',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '.',\n",
              " 'For',\n",
              " 'instance',\n",
              " ',',\n",
              " 'the',\n",
              " 'term',\n",
              " 'neural',\n",
              " 'machine',\n",
              " 'translation',\n",
              " '(',\n",
              " 'NMT',\n",
              " ')',\n",
              " 'emphasizes',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'deep',\n",
              " 'learning-based',\n",
              " 'approaches',\n",
              " 'to',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'directly',\n",
              " 'learn',\n",
              " 'sequence-to-sequence',\n",
              " 'transformations',\n",
              " ',',\n",
              " 'obviating',\n",
              " 'the',\n",
              " 'need',\n",
              " 'for',\n",
              " 'intermediate',\n",
              " 'steps',\n",
              " 'such',\n",
              " 'as',\n",
              " 'word',\n",
              " 'alignment',\n",
              " 'and',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'that',\n",
              " 'was',\n",
              " 'used',\n",
              " 'in',\n",
              " 'statistical',\n",
              " 'machine',\n",
              " 'translation',\n",
              " '(',\n",
              " 'SMT',\n",
              " ')']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwoJDzYvgDCK"
      },
      "source": [
        "Sentence Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cob8qJ4-dQ7b",
        "outputId": "5e58860c-7550-4601-90ba-e6cb3d84e426"
      },
      "source": [
        "sent_tokenize(text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A major drawback of statistical methods is that they require elaborate feature engineering.',\n",
              " 'Since the early 2010s,[16] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning.',\n",
              " 'Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing).',\n",
              " 'In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing.',\n",
              " 'For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcDlNZVLe5CM"
      },
      "source": [
        "**Romoval of Stopwords and Punctuations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXWU-DkBdRCR"
      },
      "source": [
        "stop = stopwords.words('english')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vqDpI-bdRIn",
        "outputId": "b0d15f04-5ce0-4f05-def0-71b1cdfe3e4e"
      },
      "source": [
        "len(stop)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNkR_5VAdtWX",
        "outputId": "2288e955-7c18-4a72-d294-148db1cebbeb"
      },
      "source": [
        "stop"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcN9td3Qdtc7"
      },
      "source": [
        "punkt = list(punctuation)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpUly1judtkK",
        "outputId": "57fd846d-ce79-4e76-9d73-04e763ab2d27"
      },
      "source": [
        "punkt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVZR86mydtpK"
      },
      "source": [
        "bad_tokens = stop + punkt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCIRp_0bdtt4",
        "outputId": "ccda9b15-5719-4490-bc08-de69152717c4"
      },
      "source": [
        "bad_tokens"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxdnW_fldtz9",
        "outputId": "341a4a72-c4b3-42ac-9540-63341f6748da"
      },
      "source": [
        "len(bad_tokens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI80uX5zfKgC"
      },
      "source": [
        "**After removal of Stopwords and Punctuations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc4dZ0_Idt4Q"
      },
      "source": [
        "final_tokens = [t for t in tokens if t not in bad_tokens]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me9ywO_idt8X",
        "outputId": "f32ed024-1aec-4e48-a824-0947b5a2890b"
      },
      "source": [
        "len(final_tokens)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q_OMM_ZmPLN",
        "outputId": "3735ca95-848e-483d-a824-972726a32a7c"
      },
      "source": [
        "final_tokens"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'major',\n",
              " 'drawback',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'require',\n",
              " 'elaborate',\n",
              " 'feature',\n",
              " 'engineering',\n",
              " 'Since',\n",
              " 'early',\n",
              " '2010s',\n",
              " '16',\n",
              " 'field',\n",
              " 'thus',\n",
              " 'largely',\n",
              " 'abandoned',\n",
              " 'statistical',\n",
              " 'methods',\n",
              " 'shifted',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'Popular',\n",
              " 'techniques',\n",
              " 'include',\n",
              " 'use',\n",
              " 'word',\n",
              " 'embeddings',\n",
              " 'capture',\n",
              " 'semantic',\n",
              " 'properties',\n",
              " 'words',\n",
              " 'increase',\n",
              " 'end-to-end',\n",
              " 'learning',\n",
              " 'higher-level',\n",
              " 'task',\n",
              " 'e.g.',\n",
              " 'question',\n",
              " 'answering',\n",
              " 'instead',\n",
              " 'relying',\n",
              " 'pipeline',\n",
              " 'separate',\n",
              " 'intermediate',\n",
              " 'tasks',\n",
              " 'e.g.',\n",
              " 'part-of-speech',\n",
              " 'tagging',\n",
              " 'dependency',\n",
              " 'parsing',\n",
              " 'In',\n",
              " 'areas',\n",
              " 'shift',\n",
              " 'entailed',\n",
              " 'substantial',\n",
              " 'changes',\n",
              " 'NLP',\n",
              " 'systems',\n",
              " 'designed',\n",
              " 'deep',\n",
              " 'neural',\n",
              " 'network-based',\n",
              " 'approaches',\n",
              " 'may',\n",
              " 'viewed',\n",
              " 'new',\n",
              " 'paradigm',\n",
              " 'distinct',\n",
              " 'statistical',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'For',\n",
              " 'instance',\n",
              " 'term',\n",
              " 'neural',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'NMT',\n",
              " 'emphasizes',\n",
              " 'fact',\n",
              " 'deep',\n",
              " 'learning-based',\n",
              " 'approaches',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'directly',\n",
              " 'learn',\n",
              " 'sequence-to-sequence',\n",
              " 'transformations',\n",
              " 'obviating',\n",
              " 'need',\n",
              " 'intermediate',\n",
              " 'steps',\n",
              " 'word',\n",
              " 'alignment',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'used',\n",
              " 'statistical',\n",
              " 'machine',\n",
              " 'translation',\n",
              " 'SMT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpEFX3CgmtOr"
      },
      "source": [
        "**Stemming**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7qSIyR2duAi"
      },
      "source": [
        "stemmer = nltk.PorterStemmer()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH5jKZMuduEj"
      },
      "source": [
        "word_stem=[stemmer.stem(w) for w in final_tokens]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBNHreaXuUyp",
        "outputId": "e98ec291-87cd-427a-bc77-349ff5172280"
      },
      "source": [
        "print(word_stem)\r\n",
        "len(word_stem)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'major', 'drawback', 'statist', 'method', 'requir', 'elabor', 'featur', 'engin', 'sinc', 'earli', '2010', '16', 'field', 'thu', 'larg', 'abandon', 'statist', 'method', 'shift', 'neural', 'network', 'machin', 'learn', 'popular', 'techniqu', 'includ', 'use', 'word', 'embed', 'captur', 'semant', 'properti', 'word', 'increas', 'end-to-end', 'learn', 'higher-level', 'task', 'e.g.', 'question', 'answer', 'instead', 'reli', 'pipelin', 'separ', 'intermedi', 'task', 'e.g.', 'part-of-speech', 'tag', 'depend', 'pars', 'In', 'area', 'shift', 'entail', 'substanti', 'chang', 'nlp', 'system', 'design', 'deep', 'neural', 'network-bas', 'approach', 'may', 'view', 'new', 'paradigm', 'distinct', 'statist', 'natur', 'languag', 'process', 'for', 'instanc', 'term', 'neural', 'machin', 'translat', 'nmt', 'emphas', 'fact', 'deep', 'learning-bas', 'approach', 'machin', 'translat', 'directli', 'learn', 'sequence-to-sequ', 'transform', 'obviat', 'need', 'intermedi', 'step', 'word', 'align', 'languag', 'model', 'use', 'statist', 'machin', 'translat', 'smt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwotqFTzp6W2"
      },
      "source": [
        "**Lemmitizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cIL3JpAduLj"
      },
      "source": [
        "lemma = WordNetLemmatizer()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bgvgl6iduO2"
      },
      "source": [
        "word_lemma=[lemma.lemmatize(w) for w in final_tokens]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtxZNH3CduSk",
        "outputId": "accb0689-5b35-4310-9151-9b806e88e634"
      },
      "source": [
        "print(word_lemma)\r\n",
        "len(word_lemma)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'major', 'drawback', 'statistical', 'method', 'require', 'elaborate', 'feature', 'engineering', 'Since', 'early', '2010s', '16', 'field', 'thus', 'largely', 'abandoned', 'statistical', 'method', 'shifted', 'neural', 'network', 'machine', 'learning', 'Popular', 'technique', 'include', 'use', 'word', 'embeddings', 'capture', 'semantic', 'property', 'word', 'increase', 'end-to-end', 'learning', 'higher-level', 'task', 'e.g.', 'question', 'answering', 'instead', 'relying', 'pipeline', 'separate', 'intermediate', 'task', 'e.g.', 'part-of-speech', 'tagging', 'dependency', 'parsing', 'In', 'area', 'shift', 'entailed', 'substantial', 'change', 'NLP', 'system', 'designed', 'deep', 'neural', 'network-based', 'approach', 'may', 'viewed', 'new', 'paradigm', 'distinct', 'statistical', 'natural', 'language', 'processing', 'For', 'instance', 'term', 'neural', 'machine', 'translation', 'NMT', 'emphasizes', 'fact', 'deep', 'learning-based', 'approach', 'machine', 'translation', 'directly', 'learn', 'sequence-to-sequence', 'transformation', 'obviating', 'need', 'intermediate', 'step', 'word', 'alignment', 'language', 'modeling', 'used', 'statistical', 'machine', 'translation', 'SMT']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp-Cd8ZIduWJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}